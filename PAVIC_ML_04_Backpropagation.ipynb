{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNngT7wDetVUl5p3cTBW10i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mafaldasalomao/pavic_treinamento_ml/blob/main/PAVIC_ML_04_Backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "xSaoX9nyOAUq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A melhor maneira de pensar em redes neurais é como circuitos de valores reais. Mas, ao invés de valores booleanos, valores reais e, ao invés de portas lógicas como **and** ou **or**, portas binárias (dois operandos) como $*$ (multiplicação), + (adição), max, exp, etc. Além disso, também teremos **gradientes** fluindo pelo circuito, mas na direção oposta."
      ],
      "metadata": {
        "id": "id9SLPA__hOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forwardMultiplyGate(a, b):\n",
        "  return a * b"
      ],
      "metadata": {
        "id": "Y0f-wxW8_FMQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De forma matemática, a gente pode considerar que essa porta implementa a seguinte função:\n",
        "\n",
        "$$f(x,y)=x*y$$"
      ],
      "metadata": {
        "id": "4XcXrk9o_l9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O Objetivo"
      ],
      "metadata": {
        "id": "6wgw17iG_rO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos imaginar que temos o seguinte problema:\n",
        "1. Nós vamos providenciar a um circuito valores específicos como entrada (x=1, y=-3)\n",
        "2. O circuito vai calcular o valor de saída (-3)\n",
        "3. A questão é: *Quanto mudar a entrada para levemente **aumentar** a saída?*\n",
        "\n",
        "No nosso caso, em que direção devemos mudar x,y para conseguir um número maior que -3? Note que, pro nosso exemplo, se x = 0.99 e y = -2.99, x$*$y = -2.96 que é maior que -3. **-2.96 é melhor (maior) que -3**, e obtivemos uma melhora de 0.04."
      ],
      "metadata": {
        "id": "qcK3YjMG_std"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estratégia 1: Busca Aleatória"
      ],
      "metadata": {
        "id": "RM1sM-VTALO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok. Isso não é trivial? A gente pode simplesmente gerar valores aleatórios, calcular a saída e guardar o melhor resultado."
      ],
      "metadata": {
        "id": "jRvXHkJOAMBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = 1, -3\n",
        "melhor_saida = forwardMultiplyGate(x,y)\n",
        "melhor_x, melhor_y = 0, 0\n",
        "\n",
        "for k in range(0,100):\n",
        "    x_try = 5*np.random.random() - 5\n",
        "    y_try = 5*np.random.random() - 5\n",
        "    out = forwardMultiplyGate(x_try, y_try)\n",
        "    \n",
        "    if out > melhor_saida:\n",
        "        melhor_saida = out\n",
        "        melhor_x, melhor_y = x_try, y_try\n",
        "\n",
        "print(melhor_x, melhor_y, forwardMultiplyGate(melhor_x, melhor_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPTRi7k3_sMO",
        "outputId": "60fca1bd-03a6-43ca-e2fc-79a55cc846c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-4.951508016242007 -4.8342603703596305 23.936878976436766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, foi bem melhor. Mas, e se tivermos milhões de entradas? É claro que essa estratégia não funcionará. Vamos tentar algo mais aprimorado."
      ],
      "metadata": {
        "id": "diiwswcmAW4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estratégia 2: Busca Aleatória Local"
      ],
      "metadata": {
        "id": "1nP7MgznAemH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um passo aleatorio em qualquer direçao, torcer para tomar a decisao correta\n",
        "agora temos um passo pra evitar um pulo muito longo\n"
      ],
      "metadata": {
        "id": "zy5QhY0nAfIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = 1, -3\n",
        "passo = 0.01\n",
        "melhor_saida = forwardMultiplyGate(x,y)\n",
        "melhor_x, melhor_y = 0, 0\n",
        "\n",
        "for k in range(0,100):\n",
        "    x_try = x + passo * (2*np.random.random() - 1)\n",
        "    y_try = y + passo * (2*np.random.random() - 1)  \n",
        "    out = forwardMultiplyGate(x_try, y_try)\n",
        "    \n",
        "    if out > melhor_saida:\n",
        "        melhor_saida = out\n",
        "        melhor_x, melhor_y = x_try, y_try\n",
        "\n",
        "print(melhor_x, melhor_y, forwardMultiplyGate(melhor_x, melhor_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqIqVaLK_Zn1",
        "outputId": "9b8ccc6a-eb80-4432-c146-223fd44649bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9914489101662263 -2.99150670342498 -2.9659260608656566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otimoooo! Demos um passinho mais controlado -2.96 é menor que -3.... mas precisamos de algo melhor, uma estratégia mais inteligente."
      ],
      "metadata": {
        "id": "9MbM8KF0BN6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estratégia 3: Gradiente Numérico"
      ],
      "metadata": {
        "id": "6gGRcmPiBZOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagine agora que a gente pega as entradas de um circuito e puxa-as para uma direção positiva. Essa força puxando $x$ e $y$ vai nos dizer como $x$ e $y$ devem mudar para aumentar a saída. Não entendeu? Vamos explicar:\n",
        "\n",
        "Se olharmos para as entradas, a gente pode intuitivamente ver que a força em $y$ deveria sempre ser positiva, porque tornando $y$ um pouquinho maior de $y=1$ para $y=-1$ aumenta a saída do circuito para $-1$, o que é bem maior que $-3$. Por outro lado, se a força em $x$ for negativa, tornando-o menor, como de $x=1$ para $x=0.5$, também aumenta a saída: $-0.5\\times-3 = -1.5$, de novo maior que $-3$.\n",
        "\n",
        "E como calcular essa força? Usando **derivadas**.\n",
        "\n",
        "> *A derivada pode ser pensada como a força que a gente aplica em cada entrada para aumentar a saída*\n",
        "\n",
        "\n",
        "E como exatamente a gente vai fazer isso? Em vez de olhar para o valor de saída, como fizemos anteriormente, nós vamos iterar sobre as cada entrada individualmente, aumentando-as bem devagar e vendo o que acontece com a saída. **A quantidade que a saída muda é a resposta da derivada**.\n",
        "\n",
        "Vamos para definição matemática. A derivada em relação a $x$ pode ser definida como:\n",
        "\n",
        "$$\\frac{\\partial f(x,y)}{\\partial x} = \\frac{f(x+h,y) - f(x,y)}{h}$$\n",
        "\n",
        "Onde $h$ é pequeno. Nós vamos, então, calcular a saída inicial $f(x,y)$ e aumentar $x$ por um valor pequeno $h$ e calcular a nova saída $f(x+h,y)$. Então, nós subtraimos esse valores para ver a diferença e dividimos por $f(x+h,y)$ para normalizar essa mudança pelo valor (arbitrário) que nós usamos.\n",
        "\n",
        "Em termos de código, teremos:"
      ],
      "metadata": {
        "id": "_i9gKYaxBZ14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = 1, -3\n",
        "out = forwardMultiplyGate(x,y) # f(x,y)\n",
        "h = 0.0001 # o h tende a 0\n",
        "\n",
        "# derivada em relação a x\n",
        "out2 = forwardMultiplyGate(x+h, y) # f(x + h, y)\n",
        "\n",
        "derivada_x = (out2- out)/h\n",
        "\n",
        "# derivada em relação a y\n",
        "out3 = forwardMultiplyGate(x, y+h) # f(x + h, y)\n",
        "\n",
        "derivada_y = (out3 - out)/h\n",
        "print(out2, out3)\n",
        "derivada_x, derivada_y "
      ],
      "metadata": {
        "id": "e1IBXIQ1BM4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec5a4ee-c3b6-4663-fbfb-6c54ebceeece"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3.0003 -2.9999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.00000000000189, 1.0000000000021103)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essas saídas representam a foça da atualização naquele ponto\n",
        "o *3* indica que a força da derivada de $x$ é maior que a força da derivada de $y$\n",
        "O sinal indica somente se a função cresce ou decresce\n",
        "\n",
        "> *A derivada em relação a alguma entrada pode ser calculada ajustando levemente aquela entrada e observando a mudança no valor da saída*\n",
        "\n",
        "A derivada é calculada sobre cada entrada, enquanto o **gradiente** representa todas as derivadas sobre as entradas concatenadas em um vetor.\n",
        "> Derivada é so um valor e o gradiente eh o vertor desses valores"
      ],
      "metadata": {
        "id": "SVHuVGboa2dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = 1, -3\n",
        "passo = 0.01\n",
        "out = forwardMultiplyGate(x, y) # f(x , y)\n",
        "x = x + passo * derivada_x # atualizamos os pesos\n",
        "y = y + passo * derivada_y\n",
        "out_new = forwardMultiplyGate(x, y)\n",
        "\n",
        "print(out_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZAQUVl4ZaSE",
        "outputId": "0c66d17e-f7e2-4c1b-e565-62bf12ef3431"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2.801199999999848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dessa forma conseguimos reduzir nossa função em poucas iterações (rodar mais 2x)"
      ],
      "metadata": {
        "id": "jieswZFNcVgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo maior nem sempre é melhor**: É importante destacar que qualquer valor de passo maior que 0.01 ia sempre funcionar melhor (por exemplo, passo = 1 gera a saída = 1). No entanto, à medida que os circuitos vão ficando mais complexos (como em redes neurais completas), a função vai ser tornando mais caótica e complexa. O gradiente garante que se você tem um passo muito pequeno (o ideal seria infinitesimal), então você definitivamente aumenta a saída seguindo aquela direção. O passo que estamos utilizando (0.01) ainda é muito grande, mas como nosso circuito é simples, podemos esperar pelo melhor resultado. Lembre-se da analogia do **escalador cego**."
      ],
      "metadata": {
        "id": "qO_-mHJQciad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estratégia 4: Gradiente Analítico"
      ],
      "metadata": {
        "id": "tRgGJWgJcmYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A estratégia que utilizamos até agora de ajustar levemente a entrada e ver o que acontece com a saída pode não ser muito cômoda na prática quando temos milhares de entradas para ajustar. Então, a gente precisa de algo melhor.\n",
        "\n",
        "Felizmente, existe uma estratégia mais fácil e muito mais rápida para calcular o gradiente: podemos usar cálculo para derivar diretamente a nossa função. Chamamos isso de **gradiente analítico** e dessa forma não precisamos ajustar levemente nada. \n",
        "\n",
        "> *O gradiente analítico evita o leve ajustamento das entradas. O circuito pode ser derivado usando cálculo.*\n",
        "\n",
        "É muito fácil calcular derivadas parciais para funções simples como $x*y$. Se você não lembra da definição, aqui está o cálculo da derivada parcial em relação a $x$ da nossa função $f(x,y)$:\n",
        "\n",
        "$$\\frac{\\partial f(x,y)}{\\partial x} = \\frac{f(x+h,y) - f(x,y)}{h}\n",
        "= \\frac{(x+h)y - xy}{h}\n",
        "= \\frac{xy + hy - xy}{h}\n",
        "= \\frac{hy}{h}\n",
        "= y$$\n",
        "\n",
        "A derivada parcial em relação em $x$ da nossa $f(x,y)$ é igual $y$. Você reparou na coincidência de $\\partial x = 3.0$, que é exatamente o valor de $y$? E que o mesmo aconteceu para $x$? **Então, a gente não precisa ajustar nada!** E nosso código fica assim:"
      ],
      "metadata": {
        "id": "8P9_J5iPco9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = -2, 3\n",
        "out = forwardMultiplyGate(x,y)\n",
        "\n"
      ],
      "metadata": {
        "id": "2ZpPemgWc311"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "É importante destacar que a Estratégia #3 reduziu a #2 para uma única vez. Porém, a #3 nos dá somente uma aproximação do gradiente, enquanto a Estratégia #4 nos dá o valor exato. Sem aproximações. O único lado negativo é que temos de saber derivar a nossa funcão.\n",
        "\n",
        "Recapitulando o que vimos até aqui:\n",
        "- __Estratégia 1__: definimos valores aleatórios em todas as iterações. Não funciona para muitas entradas.\n",
        "- __Estratégia 2__: pequenos ajustes aleatórios nas entradas e vemos qual funciona melhor. Tão ruim quando a #1.\n",
        "- __Estratégia 3__: muito melhor através do cálculo do gradiente. Independentemente de quão complicado é o circuito, o **gradiente numérico** é muito simples de se calcular (mas um pouco caro).\n",
        "- __Estratégia 4__: no final, vimos que a forma melhor, mais inteligente e mais rápida é calcular o **gradiente analítico**. O resultado é idêntico ao gradiente numérico, porém mais rápido e não precisa de ajustes."
      ],
      "metadata": {
        "id": "jClYQKl_c_LW"
      }
    }
  ]
}