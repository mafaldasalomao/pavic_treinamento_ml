{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMA28fGr1DAALpHqXxBqEfs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mafaldasalomao/pavic_treinamento_ml/blob/main/PAVIC_ML_20_DCGAN_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a DCGAN in PyTorch"
      ],
      "metadata": {
        "id": "7W6f2LqmrTCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Structure\n",
        "\n",
        "\n",
        "```\n",
        "# !tree .\n",
        ".\n",
        "├── dcgan_mnist.py\n",
        "├── output\n",
        "│   ├── epoch_0002.png\n",
        "│   ├── epoch_0004.png\n",
        "│   ├── epoch_0006.png\n",
        "│   ├── epoch_0008.png\n",
        "│   ├── epoch_0010.png\n",
        "│   ├── epoch_0012.png\n",
        "│   ├── epoch_0014.png\n",
        "│   ├── epoch_0016.png\n",
        "│   ├── epoch_0018.png\n",
        "│   └── epoch_0020.png\n",
        "├── output.gif\n",
        "└── pyimagesearch\n",
        "    ├── dcgan.py\n",
        "    └── __init__.py\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9iMS_tH-rOls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the pyimagesearch directory, we have two files:\n",
        "\n",
        "dcgan.py: Contains the complete DCGAN architecture\n",
        "__init__.py: Turns the pyimagesearch into a python directory\n",
        "In the parent directory, we have the dcgan_mnist.py script, which will train the DCGAN and draw inference from it.\n",
        "\n",
        "Apart from these, we have the output directory, which contains the epoch-wise visualization of images generated by the DCGAN Generator. Finally, we have the output.gif, which contains the visualizations converted into a gif."
      ],
      "metadata": {
        "id": "4fLSzacCrdqG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GSiPjYaJrKkH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"pyimagesearch\", exist_ok=True)\n",
        "os.makedirs(\"output\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pyimagesearch/dcgan.py\n",
        "# import the necessary packages\n",
        "from torch.nn import ConvTranspose2d\n",
        "from torch.nn import BatchNorm2d\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import LeakyReLU\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Tanh\n",
        "from torch.nn import Sigmoid\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, inputDim=100, outputChannels=1):\n",
        "        super(Generator, self).__init__()\n",
        "        # first set of CONVT => RELU => BN\n",
        "        self.ct1 = ConvTranspose2d(in_channels=inputDim,\n",
        "          out_channels=128, kernel_size=4, stride=2, padding=0,\n",
        "          bias=False)\n",
        "        self.relu1 = ReLU()\n",
        "        self.batchNorm1 = BatchNorm2d(128)\n",
        "        # second set of CONVT => RELU => BN\n",
        "        self.ct2 = ConvTranspose2d(in_channels=128, out_channels=64,\n",
        "              kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.relu2 = ReLU()\n",
        "        self.batchNorm2 = BatchNorm2d(64)\n",
        "        # last set of CONVT => RELU => BN\n",
        "        self.ct3 = ConvTranspose2d(in_channels=64, out_channels=32,\n",
        "              kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.relu3 = ReLU()\n",
        "        self.batchNorm3 = BatchNorm2d(32)\n",
        "        # apply another upsample and transposed convolution, but\n",
        "        # this time output the TANH activation\n",
        "        self.ct4 = ConvTranspose2d(in_channels=32,\n",
        "          out_channels=outputChannels, kernel_size=4, stride=2,\n",
        "          padding=1, bias=False)\n",
        "        self.tanh = Tanh()\n",
        "    def forward(self, x):\n",
        "      # pass the input through our first set of CONVT => RELU => BN\n",
        "      # layers\n",
        "      x = self.ct1(x)\n",
        "      x = self.relu1(x)\n",
        "      x = self.batchNorm1(x)\n",
        "      # pass the output from previous layer through our second\n",
        "      # CONVT => RELU => BN layer set\n",
        "      x = self.ct2(x)\n",
        "      x = self.relu2(x)\n",
        "      x = self.batchNorm2(x)\n",
        "      # pass the output from previous layer through our last set\n",
        "      # of CONVT => RELU => BN layers\n",
        "      x = self.ct3(x)\n",
        "      x = self.relu3(x)\n",
        "      x = self.batchNorm3(x)\n",
        "      # pass the output from previous layer through CONVT2D => TANH\n",
        "      # layers to get our output\n",
        "      x = self.ct4(x)\n",
        "      output = self.tanh(x)\n",
        "      # return the output\n",
        "      return output\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, depth, alpha=0.2):\n",
        "      super(Discriminator, self).__init__()\n",
        "      # first set of CONV => RELU layers\n",
        "      self.conv1 = Conv2d(in_channels=depth, out_channels=32,\n",
        "          kernel_size=4, stride=2, padding=1)\n",
        "      self.leakyRelu1 = LeakyReLU(alpha, inplace=True)\n",
        "      # second set of CONV => RELU layers\n",
        "      self.conv2 = Conv2d(in_channels=32, out_channels=64, kernel_size=4,\n",
        "          stride=2, padding=1)\n",
        "      self.leakyRelu2 = LeakyReLU(alpha, inplace=True)\n",
        "      # first (and only) set of FC => RELU layers\n",
        "      self.fc1 = Linear(in_features=3136, out_features=512)\n",
        "      self.leakyRelu3 = LeakyReLU(alpha, inplace=True)\n",
        "      # sigmoid layer outputting a single value\n",
        "      self.fc2 = Linear(in_features=512, out_features=1)\n",
        "      self.sigmoid = Sigmoid()\n",
        "  def forward(self, x):\n",
        "      # pass the input through first set of CONV => RELU layers\n",
        "      x = self.conv1(x)\n",
        "      x = self.leakyRelu1(x)\n",
        "      # pass the output from the previous layer through our second\n",
        "      # set of CONV => RELU layers\n",
        "      x = self.conv2(x)\n",
        "      x = self.leakyRelu2(x)\n",
        "      # flatten the output from the previous layer and pass it\n",
        "      # through our first (and only) set of FC => RELU layers\n",
        "      x = flatten(x, 1)\n",
        "      x = self.fc1(x)\n",
        "      x = self.leakyRelu3(x)\n",
        "      # pass the output from the previous layer through our sigmoid\n",
        "      # layer outputting a single value\n",
        "      x = self.fc2(x)\n",
        "      output = self.sigmoid(x)\n",
        "      # return the output\n",
        "      return output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdHmIkc2rqY-",
        "outputId": "b438e01f-c15c-4909-aae5-17f2e8f72468"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pyimagesearch/dcgan.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training The DCGAN\n"
      ],
      "metadata": {
        "id": "4q4jCnMRsbk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dcgan_mnist.py\n",
        "# USAGE\n",
        "# python dcgan_mnist.py --output output\n",
        "# import the necessary packages\n",
        "from pyimagesearch.dcgan import Generator\n",
        "from pyimagesearch.dcgan import Discriminator\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "from sklearn.utils import shuffle\n",
        "from imutils import build_montages\n",
        "from torch.optim import Adam\n",
        "from torch.nn import BCELoss\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "# custom weights initialization called on generator and discriminator\n",
        "def weights_init(model):\n",
        "\t# get the class name\n",
        "\tclassname = model.__class__.__name__\n",
        "\t# check if the classname contains the word \"conv\"\n",
        "\tif classname.find(\"Conv\") != -1:\n",
        "\t\t# intialize the weights from normal distribution\n",
        "\t\tnn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "\t# otherwise, check if the name contains the word \"BatcnNorm\"\n",
        "\telif classname.find(\"BatchNorm\") != -1:\n",
        "\t\t# intialize the weights from normal distribution and set the\n",
        "\t\t# bias to 0\n",
        "\t\tnn.init.normal_(model.weight.data, 1.0, 0.02)\n",
        "\t\tnn.init.constant_(model.bias.data, 0)\n",
        "# construct the argument parse and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-o\", \"--output\", required=True,\n",
        "\thelp=\"path to output directory\")\n",
        "ap.add_argument(\"-e\", \"--epochs\", type=int, default=20,\n",
        "\thelp=\"# epochs to train for\")\n",
        "ap.add_argument(\"-b\", \"--batch-size\", type=int, default=128,\n",
        "\thelp=\"batch size for training\")\n",
        "args = vars(ap.parse_args())\n",
        "# store the epochs and batch size in convenience variables\n",
        "NUM_EPOCHS = args[\"epochs\"]\n",
        "BATCH_SIZE = args[\"batch_size\"]\n",
        "# set the device we will be using\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# define data transforms\n",
        "dataTransforms = transforms.Compose([\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize((0.5), (0.5))]\n",
        ")\n",
        "# load the MNIST dataset and stack the training and testing data\n",
        "# points so we have additional training data\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "trainData = MNIST(root=\"data\", train=True, download=True,\n",
        "\ttransform=dataTransforms)\n",
        "testData = MNIST(root=\"data\", train=False, download=True,\n",
        "\ttransform=dataTransforms)\n",
        "data = torch.utils.data.ConcatDataset((trainData, testData))\n",
        "# initialize our dataloader\n",
        "dataloader = DataLoader(data, shuffle=True,\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "# calculate steps per epoch\n",
        "stepsPerEpoch = len(dataloader.dataset) // BATCH_SIZE\n",
        "# build the generator, initialize it's weights, and flash it to the\n",
        "# current device\n",
        "print(\"[INFO] building generator...\")\n",
        "gen = Generator(inputDim=100, outputChannels=1)\n",
        "gen.apply(weights_init)\n",
        "gen.to(DEVICE)\n",
        "# build the discriminator, initialize it's weights, and flash it to\n",
        "# the current device\n",
        "print(\"[INFO] building discriminator...\")\n",
        "disc = Discriminator(depth=1)\n",
        "disc.apply(weights_init)\n",
        "disc.to(DEVICE)\n",
        "# initialize optimizer for both generator and discriminator\n",
        "genOpt = Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999),\n",
        "\tweight_decay=0.0002 / NUM_EPOCHS)\n",
        "discOpt = Adam(disc.parameters(), lr=0.0002, betas=(0.5, 0.999),\n",
        "\tweight_decay=0.0002 / NUM_EPOCHS)\n",
        "# initialize BCELoss function\n",
        "criterion = BCELoss()\n",
        "# randomly generate some benchmark noise so we can consistently\n",
        "# visualize how the generative modeling is learning\n",
        "print(\"[INFO] starting training...\")\n",
        "benchmarkNoise = torch.randn(256, 100, 1, 1, device=DEVICE)\n",
        "# define real and fake label values\n",
        "realLabel = 1\n",
        "fakeLabel = 0\n",
        "# loop over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # show epoch information and compute the number of batches per\n",
        "    # epoch\n",
        "    print(\"[INFO] starting epoch {} of {}...\".format(epoch + 1,\n",
        "      NUM_EPOCHS))\n",
        "    # initialize current epoch loss for generator and discriminator\n",
        "    epochLossG = 0\n",
        "    epochLossD = 0\n",
        "    for x in dataloader:\n",
        "      # zero out the discriminator gradients\n",
        "      disc.zero_grad()\n",
        "      # grab the images and send them to the device\n",
        "      images = x[0]\n",
        "      images = images.to(DEVICE)\n",
        "      # get the batch size and create a labels tensor\n",
        "      bs =  images.size(0)\n",
        "      labels = torch.full((bs,), realLabel, dtype=torch.float,\n",
        "        device=DEVICE)\n",
        "      # forward pass through discriminator\n",
        "      output = disc(images).view(-1)\n",
        "      # calculate the loss on all-real batch\n",
        "      errorReal = criterion(output, labels)\n",
        "      # calculate gradients by performing a backward pass\n",
        "      errorReal.backward()\n",
        "      # randomly generate noise for the generator to predict on\n",
        "      noise = torch.randn(bs, 100, 1, 1, device=DEVICE)\n",
        "      # generate a fake image batch using the generator\n",
        "      fake = gen(noise)\n",
        "      labels.fill_(fakeLabel)\n",
        "      # perform a forward pass through discriminator using fake\n",
        "      # batch data\n",
        "      output = disc(fake.detach()).view(-1)\n",
        "      errorFake = criterion(output, labels)\n",
        "      # calculate gradients by performing a backward pass\n",
        "      errorFake.backward()\n",
        "      # compute the error for discriminator and update it\n",
        "      errorD = errorReal + errorFake\n",
        "      discOpt.step()\n",
        "      # set all generator gradients to zero\n",
        "      gen.zero_grad()\n",
        "      # update the labels as fake labels are real for the generator\n",
        "      # and perform a forward pass  of fake data batch through the\n",
        "      # discriminator\n",
        "      labels.fill_(realLabel)\n",
        "      output = disc(fake).view(-1)\n",
        "      # calculate generator's loss based on output from\n",
        "      # discriminator and calculate gradients for generator\n",
        "      errorG = criterion(output, labels)\n",
        "      errorG.backward()\n",
        "      # update the generator\n",
        "      genOpt.step()\n",
        "      # add the current iteration loss of discriminator and\n",
        "      # generator\n",
        "      epochLossD += errorD\n",
        "      epochLossG += errorG\n",
        "      # display training information to disk\n",
        "    print(\"[INFO] Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(\n",
        "      epochLossG / stepsPerEpoch, epochLossD / stepsPerEpoch))\n",
        "    # check to see if we should visualize the output of the\n",
        "    # generator model on our benchmark data\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "      # set the generator in evaluation phase, make predictions on\n",
        "      # the benchmark noise, scale it back to the range [0, 255],\n",
        "      # and generate the montage\n",
        "      gen.eval()\n",
        "      images = gen(benchmarkNoise)\n",
        "      images = images.detach().cpu().numpy().transpose((0, 2, 3, 1))\n",
        "      images = ((images * 127.5) + 127.5).astype(\"uint8\")\n",
        "      images = np.repeat(images, 3, axis=-1)\n",
        "      vis = build_montages(images, (28, 28), (16, 16))[0]\n",
        "      # build the output path and write the visualization to disk\n",
        "      p = os.path.join(args[\"output\"], \"epoch_{}.png\".format(\n",
        "        str(epoch + 1).zfill(4)))\n",
        "      cv2.imwrite(p, vis)\n",
        "      # set the generator to training mode\n",
        "      gen.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTGWwaglskQU",
        "outputId": "3948ad10-a4f5-4f54-aaed-bd02b1144901"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dcgan_mnist.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dcgan_mnist.py --output output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3WcvD3ttdAO",
        "outputId": "7ac6340d-8cf0-4b9b-987b-ccca01d5c178"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "\r  0% 0/9912422 [00:00<?, ?it/s]\r100% 9912422/9912422 [00:00<00:00, 172443202.53it/s]\n",
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "100% 28881/28881 [00:00<00:00, 168010671.05it/s]\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "100% 1648877/1648877 [00:00<00:00, 38770771.20it/s]\n",
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "100% 4542/4542 [00:00<00:00, 30876059.59it/s]\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "[INFO] building generator...\n",
            "[INFO] building discriminator...\n",
            "[INFO] starting training...\n",
            "[INFO] starting epoch 1 of 20...\n",
            "[INFO] Generator Loss: 3.6494, Discriminator Loss: 0.5438\n",
            "[INFO] starting epoch 2 of 20...\n",
            "[INFO] Generator Loss: 1.2177, Discriminator Loss: 1.0777\n",
            "[INFO] starting epoch 3 of 20...\n",
            "[INFO] Generator Loss: 1.1024, Discriminator Loss: 1.0929\n",
            "[INFO] starting epoch 4 of 20...\n",
            "[INFO] Generator Loss: 1.0145, Discriminator Loss: 1.1275\n",
            "[INFO] starting epoch 5 of 20...\n",
            "[INFO] Generator Loss: 0.9373, Discriminator Loss: 1.1884\n",
            "[INFO] starting epoch 6 of 20...\n",
            "[INFO] Generator Loss: 0.9183, Discriminator Loss: 1.2149\n",
            "[INFO] starting epoch 7 of 20...\n",
            "[INFO] Generator Loss: 0.9181, Discriminator Loss: 1.2179\n",
            "[INFO] starting epoch 8 of 20...\n",
            "[INFO] Generator Loss: 0.9197, Discriminator Loss: 1.2215\n",
            "[INFO] starting epoch 9 of 20...\n",
            "[INFO] Generator Loss: 0.9280, Discriminator Loss: 1.2213\n",
            "[INFO] starting epoch 10 of 20...\n",
            "[INFO] Generator Loss: 0.9358, Discriminator Loss: 1.2170\n",
            "[INFO] starting epoch 11 of 20...\n",
            "[INFO] Generator Loss: 0.9490, Discriminator Loss: 1.2113\n",
            "[INFO] starting epoch 12 of 20...\n",
            "[INFO] Generator Loss: 0.9601, Discriminator Loss: 1.2038\n",
            "[INFO] starting epoch 13 of 20...\n",
            "[INFO] Generator Loss: 0.9715, Discriminator Loss: 1.1967\n",
            "[INFO] starting epoch 14 of 20...\n",
            "[INFO] Generator Loss: 0.9895, Discriminator Loss: 1.1865\n",
            "[INFO] starting epoch 15 of 20...\n",
            "[INFO] Generator Loss: 1.0086, Discriminator Loss: 1.1694\n",
            "[INFO] starting epoch 16 of 20...\n",
            "[INFO] Generator Loss: 1.0283, Discriminator Loss: 1.1610\n",
            "[INFO] starting epoch 17 of 20...\n",
            "[INFO] Generator Loss: 1.0491, Discriminator Loss: 1.1430\n",
            "[INFO] starting epoch 18 of 20...\n",
            "[INFO] Generator Loss: 1.0699, Discriminator Loss: 1.1336\n",
            "[INFO] starting epoch 19 of 20...\n",
            "[INFO] Generator Loss: 1.0931, Discriminator Loss: 1.1215\n",
            "[INFO] starting epoch 20 of 20...\n",
            "[INFO] Generator Loss: 1.1106, Discriminator Loss: 1.1110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DCGAN Training Results and Visualizations"
      ],
      "metadata": {
        "id": "rTXmtcc0tTU8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Codigo fonte](https://pyimagesearch.com/2021/10/25/training-a-dcgan-in-pytorch/)"
      ],
      "metadata": {
        "id": "yOEKym7Atkne"
      }
    }
  ]
}